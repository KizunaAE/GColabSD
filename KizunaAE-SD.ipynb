{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KizunaAE/GColabSD/blob/main/KizunaAE-SD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anqY-GmKTL8V"
      },
      "source": [
        "# **StableDiffusion InvokeAI Base Cloud version**\n",
        "\n",
        "\n",
        "\n",
        "_You don't need additional Google Drive storage because uploaded models are not stored on your Google Drive. After the session ends, all data will be deleted._"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "JQ5qVdNPFqYJ"
      },
      "outputs": [],
      "source": [
        "#@markdown # **STEP 1**\n",
        "#@markdown ## Requirements\n",
        "#@markdown It might finished with error but is not the error, just execute the next cell\n",
        "\n",
        "from IPython.display import clear_output\n",
        "\n",
        "%cd /content\n",
        "!git clone https://github.com/KizunaAE/InvokeAI\n",
        "!pip install -q dependency_injector diffusers einops eventlet facexlib flask_cors flask_socketio flaskwebgui getpass_asterisk huggingface-hub\n",
        "!pip install -q kornia omegaconf pudb pyreadline3 pytorch-lightning realesrgan streamlit taming-transformers-rom1504 test-tube torch-fidelity\n",
        "!pip install -q torchmetrics transformers picklescan\n",
        "!pip install -q pillow xformers==0.0.22 triton==2.0.0 -U\n",
        "clear_output()\n",
        "\n",
        "!pip install -q git+https://github.com/invoke-ai/GFPGAN@basicsr-1.4.2#egg=gfpgan\n",
        "!pip install -q git+https://github.com/openai/CLIP.git@main#egg=clip\n",
        "!pip install -q git+https://github.com/Birch-san/k-diffusion.git@mps#egg=k-diffusion\n",
        "!pip install -q git+https://github.com/invoke-ai/clipseg.git@relaxed-python-requirement#egg=clipseg\n",
        "!pip install -q git+https://github.com/invoke-ai/PyPatchMatch@0.1.4#egg=pypatchmatch\n",
        "%cd /content/InvokeAI/\n",
        "!pip install -q -e .\n",
        "clear_output()\n",
        "\n",
        "\n",
        "!wget https://raw.githubusercontent.com/KizunaAE/InvokeAI-colab/main/INITIAL_MODELS.yaml -O /content/InvokeAI/invokeai/configs/INITIAL_MODELS.yaml\n",
        "clear_output()\n",
        "\n",
        "print('\u001b[1;32mDone!')\n",
        "\n",
        "!pip install python-socketio==5.9.0\n",
        "clear_output()\n",
        "\n",
        "#exit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "aBZ0AbI-U_zk"
      },
      "outputs": [],
      "source": [
        "#@markdown # **STEP 2**\n",
        "#@markdown ## Downloading models _(checkpoints, LoRAs, ControlNets, etc.)_\n",
        "#@markdown To configure the downloading of models, edit this file:\n",
        "#@markdown _/content/InvokeAI/invokeai/configs/INITIAL_MODELS.yaml_\n",
        "\n",
        "#@markdown P.S. It's fully explained in the tutorial.\n",
        "from IPython.display import clear_output\n",
        "\n",
        "%cd /content/InvokeAI/\n",
        "!python /content/InvokeAI/scripts/invokeai-model-install.py --root_dir /content/db --yes\n",
        "\n",
        "clear_output()\n",
        "print('\u001b[1;32mDone! All models downloaded successfully ðŸ™ƒ')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWoTrZLRP5zh",
        "outputId": "ea4ada65-3a56-48f9-a79b-24701e233821"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/InvokeAI\n",
            "\u001b[1mhttp\u001b[0m (80)\n",
            "http://ofrjqcdimnpayvkfa25qet7wampjljkup5wudiyxqygsbs3hd2qq.remote.moe/\n",
            "\n",
            "$\n",
            " \n",
            "2024-01-02 03:19:07.449405: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-01-02 03:19:07.449519: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-01-02 03:19:07.537949: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-01-02 03:19:09.798476: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional_tensor.py:5: UserWarning: The torchvision.transforms.functional_tensor module is deprecated in 0.15 and will be **removed in 0.17**. Please don't rely on it. You probably just need to use APIs in torchvision.transforms.functional or in torchvision.transforms.v2.functional.\n",
            "  warnings.warn(\n",
            ">> patchmatch.patch_match: INFO - Compiling and loading c extensions from \"/usr/local/lib/python3.10/dist-packages/patchmatch\".\n",
            ">> patchmatch.patch_match: WARNING - patchmatch failed to load or compile.\n",
            ">> patchmatch.patch_match: WARNING - Refer to https://github.com/invoke-ai/InvokeAI/blob/main/docs/installation/INSTALL_PATCHMATCH.md for installation instructions.\n",
            "\u001b[38;20m[2024-01-02 03:19:19,165]::[InvokeAI]::INFO --> Patchmatch not loaded (nonfatal)\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:19:20,637]::[uvicorn.error]::INFO --> Started server process [27679]\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:19:20,637]::[uvicorn.error]::INFO --> Waiting for application startup.\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:19:20,637]::[InvokeAI]::INFO --> InvokeAI version 3.1.0\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:19:20,638]::[InvokeAI]::INFO --> Root directory = /content/db\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:19:20,644]::[InvokeAI]::INFO --> GPU device = cuda Tesla T4\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:19:20,650]::[InvokeAI]::INFO --> Scanning /content/db/models for new models\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:19:21,025]::[InvokeAI]::INFO --> Scanned 6 files and directories, imported 0 models\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:19:21,029]::[InvokeAI]::INFO --> Model manager service initialized\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:19:21,044]::[uvicorn.error]::INFO --> Application startup complete.\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:19:21,044]::[uvicorn.error]::INFO --> Uvicorn running on http://127.0.0.1:9090 (Press CTRL+C to quit)\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:19:28,751]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /socket.io/?EIO=4&transport=polling&t=Op8Bi6b HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:19:38,510]::[InvokeAI]::INFO --> NSFW checker initialized\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:19:38,511]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/app/config HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:19:38,512]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/app/version HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:19:38,514]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/models/?base_models=sd-1&base_models=sd-2&base_models=sdxl&model_type=main HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:19:38,514]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/models/?model_type=embedding HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:19:38,515]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/models/?base_models=sd-1&base_models=sd-2&base_models=sdxl&model_type=onnx HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:19:38,516]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/models/?model_type=vae HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:19:38,518]::[uvicorn.error]::INFO --> ('110.136.55.67', 0) - \"WebSocket /socket.io/?EIO=4&transport=websocket&sid=d3bRpNamoM_040wNAAAA\" [accepted]\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:19:38,519]::[uvicorn.error]::INFO --> connection open\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:19:38,816]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/images/i/93c24596-a78d-468b-b13b-7238d9696f3e.png HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:19:38,826]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/models/?model_type=controlnet HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:19:38,933]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/images/i/8f822843-b417-4eac-bff2-57e837827f00.png HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:19:38,943]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/models/?model_type=lora HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:19:38,944]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/images/?board_id=none&categories=general&is_intermediate=false&limit=0&offset=0 HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:19:38,946]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/boards/?all=true HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:19:39,117]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/images/?board_id=none&categories=control&categories=mask&categories=user&categories=other&is_intermediate=false&limit=0&offset=0 HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:19:39,143]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/images/?board_id=none&categories=general&is_intermediate=false&limit=100&offset=0 HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:19:39,314]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /socket.io/?EIO=4&transport=polling&t=Op8BiDd&sid=d3bRpNamoM_040wNAAAA HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:19:39,316]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"POST /socket.io/?EIO=4&transport=polling&t=Op8BiDZ&sid=d3bRpNamoM_040wNAAAA HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:19:41,117]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /openapi.json HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:19:41,119]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/models/?base_models=sd-1&base_models=sd-2&base_models=sdxl&model_type=main HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:19:41,122]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/models/?model_type=controlnet HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:19:41,123]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/models/?model_type=embedding HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:19:41,124]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/models/?model_type=vae HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:19:41,124]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/models/?model_type=lora HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:19:41,778]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/app/config HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:19:41,779]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/app/version HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:20:23,060]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"POST /api/v1/sessions/ HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:20:23,972]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"PUT /api/v1/sessions/ba1884f7-bb4d-41c7-b28c-9f4a7e5b8da1/invoke?all=true HTTP/1.1\" 202\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:20:24,056]::[InvokeAI]::INFO --> Loading model /content/db/models/.cache/dae628d124664ea171e7a78bb07f739f, type sd-1:main:tokenizer\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:20:24,904]::[InvokeAI]::INFO --> Loading model /content/db/models/.cache/dae628d124664ea171e7a78bb07f739f, type sd-1:main:text_encoder\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:20:31,646]::[InvokeAI]::INFO --> Loading model /content/db/models/sd-1/lora/more_details.safetensors, type sd-1:lora\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:20:41,060]::[InvokeAI]::INFO --> Loading model /content/db/models/.cache/dae628d124664ea171e7a78bb07f739f, type sd-1:main:unet\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:20:54,181]::[InvokeAI]::INFO --> Loading model /content/db/models/.cache/dae628d124664ea171e7a78bb07f739f, type sd-1:main:scheduler\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:20:55,013]::[InvokeAI]::INFO --> Loading model /content/db/models/sd-1/controlnet/canny, type sd-1:controlnet\u001b[0m\n",
            "100% 49/49 [00:50<00:00,  1.03s/it]\n",
            "\u001b[38;20m[2024-01-02 03:21:56,121]::[InvokeAI]::INFO --> Loading model /content/db/models/core/convert/sd-vae-ft-mse, type sd-1:vae\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:22:03,955]::[InvokeAI]::INFO --> Graph stats: ba1884f7-bb4d-41c7-b28c-9f4a7e5b8da1\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:22:03,955]::[InvokeAI]::INFO -->                           Node   Calls  Seconds  VRAM Used\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:22:03,956]::[InvokeAI]::INFO -->              main_model_loader     1     0.011s     0.000G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:22:03,956]::[InvokeAI]::INFO -->                      clip_skip     1     0.010s     0.000G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:22:03,956]::[InvokeAI]::INFO -->                    lora_loader     1     0.013s     0.000G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:22:03,957]::[InvokeAI]::INFO -->                         compel     2    16.749s     0.248G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:22:03,957]::[InvokeAI]::INFO -->                     vae_loader     1     0.011s     0.244G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:22:03,957]::[InvokeAI]::INFO -->                       rand_int     1     0.011s     0.244G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:22:03,957]::[InvokeAI]::INFO -->                  range_of_size     1     0.010s     0.244G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:22:03,958]::[InvokeAI]::INFO -->                     controlnet     1     0.010s     0.244G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:22:03,958]::[InvokeAI]::INFO -->                        collect     1     0.010s     0.244G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:22:03,958]::[InvokeAI]::INFO -->                        iterate     1     0.011s     0.244G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:22:03,958]::[InvokeAI]::INFO -->                          noise     1     0.018s     0.244G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:22:03,959]::[InvokeAI]::INFO -->                denoise_latents     1    75.011s     2.889G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:22:03,959]::[InvokeAI]::INFO -->           metadata_accumulator     1     0.013s     2.304G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:22:03,959]::[InvokeAI]::INFO -->                            l2i     1     7.830s     3.824G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:22:03,959]::[InvokeAI]::INFO --> TOTAL GRAPH EXECUTION TIME:   99.719s\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:22:03,960]::[InvokeAI]::INFO --> RAM used by InvokeAI process: 7.08G (+1.676G)\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:22:03,960]::[InvokeAI]::INFO --> RAM used to load models: 2.67G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:22:03,960]::[InvokeAI]::INFO --> VRAM in use: 0.303G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:22:03,960]::[InvokeAI]::INFO --> RAM cache statistics:\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:22:03,961]::[InvokeAI]::INFO -->    Model cache hits: 4\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:22:03,961]::[InvokeAI]::INFO -->    Model cache misses: 7\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:22:03,961]::[InvokeAI]::INFO -->    Models cached: 7\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:22:03,961]::[InvokeAI]::INFO -->    Models cleared from cache: 0\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:22:03,962]::[InvokeAI]::INFO -->    Cache high water mark: 2.67/6.00G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:22:04,441]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/images/i/64859a6e-5797-4541-9b4d-56a59f84e434.png HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:22:04,923]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/images/?board_id=none&categories=general&is_intermediate=false&limit=0&offset=0 HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:22:05,038]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/images/?board_id=none&categories=control&categories=mask&categories=user&categories=other&is_intermediate=false&limit=0&offset=0 HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:22:05,048]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/images/i/64859a6e-5797-4541-9b4d-56a59f84e434.png/full HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:22:05,049]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/images/i/64859a6e-5797-4541-9b4d-56a59f84e434.png/thumbnail HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:22:23,777]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/images/i/64859a6e-5797-4541-9b4d-56a59f84e434.png/full HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:47:45,116]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"POST /api/v1/sessions/ HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:47:45,508]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"PUT /api/v1/sessions/1998f559-48a2-44eb-89db-06a0d984fa46/invoke?all=true HTTP/1.1\" 202\u001b[0m\n",
            "100% 49/49 [00:35<00:00,  1.39it/s]\n",
            "\u001b[38;20m[2024-01-02 03:48:32,152]::[InvokeAI]::INFO --> Graph stats: 1998f559-48a2-44eb-89db-06a0d984fa46\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:48:32,152]::[InvokeAI]::INFO -->                           Node   Calls  Seconds  VRAM Used\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:48:32,153]::[InvokeAI]::INFO -->              main_model_loader     1     0.013s     0.303G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:48:32,153]::[InvokeAI]::INFO -->                      clip_skip     1     0.014s     0.303G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:48:32,153]::[InvokeAI]::INFO -->                    lora_loader     1     0.013s     0.303G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:48:32,154]::[InvokeAI]::INFO -->                         compel     2     3.754s     0.303G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:48:32,154]::[InvokeAI]::INFO -->                     vae_loader     1     0.009s     0.244G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:48:32,154]::[InvokeAI]::INFO -->                       rand_int     1     0.011s     0.244G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:48:32,154]::[InvokeAI]::INFO -->                  range_of_size     1     0.011s     0.244G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:48:32,155]::[InvokeAI]::INFO -->                        iterate     1     0.010s     0.244G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:48:32,155]::[InvokeAI]::INFO -->                          noise     1     0.015s     0.244G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:48:32,155]::[InvokeAI]::INFO -->                denoise_latents     1    38.475s     2.309G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:48:32,155]::[InvokeAI]::INFO -->           metadata_accumulator     1     0.014s     1.859G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:48:32,156]::[InvokeAI]::INFO -->                            l2i     1     4.056s     3.823G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:48:32,156]::[InvokeAI]::INFO --> TOTAL GRAPH EXECUTION TIME:   46.393s\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:48:32,156]::[InvokeAI]::INFO --> RAM used by InvokeAI process: 8.11G (+0.833G)\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:48:32,156]::[InvokeAI]::INFO --> RAM used to load models: 1.99G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:48:32,157]::[InvokeAI]::INFO --> VRAM in use: 0.301G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:48:32,157]::[InvokeAI]::INFO --> RAM cache statistics:\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:48:32,158]::[InvokeAI]::INFO -->    Model cache hits: 10\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:48:32,158]::[InvokeAI]::INFO -->    Model cache misses: 0\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:48:32,158]::[InvokeAI]::INFO -->    Models cached: 7\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:48:32,158]::[InvokeAI]::INFO -->    Models cleared from cache: 0\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:48:32,159]::[InvokeAI]::INFO -->    Cache high water mark: 2.67/6.00G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:48:32,695]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/images/i/2296ca84-bf2a-4b36-9ec8-10c1de637177.png HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:48:33,192]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/images/?board_id=none&categories=general&is_intermediate=false&limit=0&offset=0 HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:48:33,308]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/images/?board_id=none&categories=control&categories=mask&categories=user&categories=other&is_intermediate=false&limit=0&offset=0 HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:48:33,395]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/images/i/2296ca84-bf2a-4b36-9ec8-10c1de637177.png/thumbnail HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:48:33,450]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/images/i/2296ca84-bf2a-4b36-9ec8-10c1de637177.png/full HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:48:52,315]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"POST /api/v1/sessions/ HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:48:52,683]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"PUT /api/v1/sessions/4cc1f66a-fa1b-4230-858e-79a820695a60/invoke?all=true HTTP/1.1\" 202\u001b[0m\n",
            "100% 49/49 [00:36<00:00,  1.34it/s]\n",
            "\u001b[38;20m[2024-01-02 03:49:38,095]::[InvokeAI]::INFO --> Graph stats: 4cc1f66a-fa1b-4230-858e-79a820695a60\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:49:38,095]::[InvokeAI]::INFO -->                           Node   Calls  Seconds  VRAM Used\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:49:38,096]::[InvokeAI]::INFO -->              main_model_loader     1     0.013s     0.301G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:49:38,096]::[InvokeAI]::INFO -->                      clip_skip     1     0.011s     0.301G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:49:38,096]::[InvokeAI]::INFO -->                    lora_loader     1     0.011s     0.301G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:49:38,096]::[InvokeAI]::INFO -->                         compel     2     2.381s     0.301G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:49:38,097]::[InvokeAI]::INFO -->                     vae_loader     1     0.010s     0.245G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:49:38,097]::[InvokeAI]::INFO -->                       rand_int     1     0.011s     0.245G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:49:38,097]::[InvokeAI]::INFO -->                  range_of_size     1     0.010s     0.245G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:49:38,097]::[InvokeAI]::INFO -->                        iterate     1     0.011s     0.245G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:49:38,097]::[InvokeAI]::INFO -->                          noise     1     0.016s     0.245G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:49:38,098]::[InvokeAI]::INFO -->                denoise_latents     1    39.239s     2.309G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:49:38,098]::[InvokeAI]::INFO -->           metadata_accumulator     1     0.012s     1.859G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:49:38,098]::[InvokeAI]::INFO -->                            l2i     1     3.448s     3.823G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:49:38,098]::[InvokeAI]::INFO --> TOTAL GRAPH EXECUTION TIME:   45.172s\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:49:38,099]::[InvokeAI]::INFO --> RAM used by InvokeAI process: 7.73G (+0.181G)\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:49:38,099]::[InvokeAI]::INFO --> RAM used to load models: 1.99G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:49:38,099]::[InvokeAI]::INFO --> VRAM in use: 0.301G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:49:38,100]::[InvokeAI]::INFO --> RAM cache statistics:\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:49:38,100]::[InvokeAI]::INFO -->    Model cache hits: 10\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:49:38,100]::[InvokeAI]::INFO -->    Model cache misses: 0\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:49:38,100]::[InvokeAI]::INFO -->    Models cached: 7\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:49:38,100]::[InvokeAI]::INFO -->    Models cleared from cache: 0\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:49:38,101]::[InvokeAI]::INFO -->    Cache high water mark: 2.67/6.00G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:49:38,639]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/images/i/e0f7404c-a997-4a5b-b1fe-f4c887b2dd3c.png HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:49:39,162]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/images/?board_id=none&categories=general&is_intermediate=false&limit=0&offset=0 HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:49:39,276]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/images/?board_id=none&categories=control&categories=mask&categories=user&categories=other&is_intermediate=false&limit=0&offset=0 HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:49:39,278]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/images/i/e0f7404c-a997-4a5b-b1fe-f4c887b2dd3c.png/thumbnail HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:49:39,410]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/images/i/e0f7404c-a997-4a5b-b1fe-f4c887b2dd3c.png/full HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:50:05,168]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"POST /api/v1/sessions/ HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:50:05,525]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"PUT /api/v1/sessions/6e7ce61a-6b8a-48e6-8c69-af25a686a277/invoke?all=true HTTP/1.1\" 202\u001b[0m\n",
            "100% 49/49 [00:16<00:00,  2.96it/s]\n",
            "\u001b[38;20m[2024-01-02 03:50:31,162]::[InvokeAI]::INFO --> Graph stats: 6e7ce61a-6b8a-48e6-8c69-af25a686a277\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:50:31,163]::[InvokeAI]::INFO -->                           Node   Calls  Seconds  VRAM Used\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:50:31,163]::[InvokeAI]::INFO -->              main_model_loader     1     0.012s     0.301G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:50:31,163]::[InvokeAI]::INFO -->                      clip_skip     1     0.013s     0.301G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:50:31,164]::[InvokeAI]::INFO -->                    lora_loader     1     0.014s     0.301G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:50:31,164]::[InvokeAI]::INFO -->                         compel     2     2.745s     0.301G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:50:31,164]::[InvokeAI]::INFO -->                     vae_loader     1     0.011s     0.245G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:50:31,165]::[InvokeAI]::INFO -->                       rand_int     1     0.010s     0.245G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:50:31,165]::[InvokeAI]::INFO -->                  range_of_size     1     0.010s     0.245G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:50:31,165]::[InvokeAI]::INFO -->                        iterate     1     0.011s     0.245G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:50:31,165]::[InvokeAI]::INFO -->                          noise     1     0.016s     0.245G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:50:31,166]::[InvokeAI]::INFO -->                denoise_latents     1    19.995s     2.113G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:50:31,166]::[InvokeAI]::INFO -->           metadata_accumulator     1     0.013s     1.859G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:50:31,166]::[InvokeAI]::INFO -->                            l2i     1     2.560s     2.299G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:50:31,166]::[InvokeAI]::INFO --> TOTAL GRAPH EXECUTION TIME:   25.409s\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:50:31,167]::[InvokeAI]::INFO --> RAM used by InvokeAI process: 7.94G (+0.071G)\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:50:31,167]::[InvokeAI]::INFO --> RAM used to load models: 1.99G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:50:31,168]::[InvokeAI]::INFO --> VRAM in use: 0.301G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:50:31,168]::[InvokeAI]::INFO --> RAM cache statistics:\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:50:31,168]::[InvokeAI]::INFO -->    Model cache hits: 10\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:50:31,169]::[InvokeAI]::INFO -->    Model cache misses: 0\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:50:31,169]::[InvokeAI]::INFO -->    Models cached: 7\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:50:31,169]::[InvokeAI]::INFO -->    Models cleared from cache: 0\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:50:31,169]::[InvokeAI]::INFO -->    Cache high water mark: 2.67/6.00G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:50:31,649]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/images/i/9c03dfdb-5e8d-481c-b02d-cf9cd0daf040.png HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:50:32,058]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/images/i/9c03dfdb-5e8d-481c-b02d-cf9cd0daf040.png/full HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:50:32,862]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/images/?board_id=none&categories=control&categories=mask&categories=user&categories=other&is_intermediate=false&limit=0&offset=0 HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:50:32,863]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/images/?board_id=none&categories=general&is_intermediate=false&limit=0&offset=0 HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:50:32,865]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/images/i/9c03dfdb-5e8d-481c-b02d-cf9cd0daf040.png/full HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:50:32,865]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/images/i/9c03dfdb-5e8d-481c-b02d-cf9cd0daf040.png/thumbnail HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:51:17,327]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"POST /api/v1/sessions/ HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:51:17,664]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"PUT /api/v1/sessions/356a2122-02c9-4364-bfe6-806f019bf942/invoke?all=true HTTP/1.1\" 202\u001b[0m\n",
            "100% 49/49 [00:16<00:00,  2.92it/s]\n",
            "\u001b[38;20m[2024-01-02 03:51:44,023]::[InvokeAI]::INFO --> Graph stats: 356a2122-02c9-4364-bfe6-806f019bf942\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:51:44,023]::[InvokeAI]::INFO -->                           Node   Calls  Seconds  VRAM Used\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:51:44,023]::[InvokeAI]::INFO -->              main_model_loader     1     0.011s     0.301G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:51:44,024]::[InvokeAI]::INFO -->                      clip_skip     1     0.011s     0.301G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:51:44,024]::[InvokeAI]::INFO -->                    lora_loader     1     0.010s     0.301G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:51:44,024]::[InvokeAI]::INFO -->                         compel     2     3.025s     0.301G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:51:44,024]::[InvokeAI]::INFO -->                     vae_loader     1     0.010s     0.245G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:51:44,025]::[InvokeAI]::INFO -->                       rand_int     1     0.011s     0.245G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:51:44,025]::[InvokeAI]::INFO -->                  range_of_size     1     0.011s     0.245G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:51:44,025]::[InvokeAI]::INFO -->                        iterate     1     0.012s     0.245G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:51:44,025]::[InvokeAI]::INFO -->                          noise     1     0.023s     0.245G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:51:44,025]::[InvokeAI]::INFO -->                denoise_latents     1    20.097s     2.114G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:51:44,026]::[InvokeAI]::INFO -->           metadata_accumulator     1     0.012s     1.859G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:51:44,026]::[InvokeAI]::INFO -->                            l2i     1     2.862s     2.299G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:51:44,026]::[InvokeAI]::INFO --> TOTAL GRAPH EXECUTION TIME:   26.097s\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:51:44,026]::[InvokeAI]::INFO --> RAM used by InvokeAI process: 8.41G (+0.555G)\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:51:44,027]::[InvokeAI]::INFO --> RAM used to load models: 1.99G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:51:44,027]::[InvokeAI]::INFO --> VRAM in use: 0.302G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:51:44,027]::[InvokeAI]::INFO --> RAM cache statistics:\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:51:44,028]::[InvokeAI]::INFO -->    Model cache hits: 10\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:51:44,028]::[InvokeAI]::INFO -->    Model cache misses: 0\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:51:44,028]::[InvokeAI]::INFO -->    Models cached: 7\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:51:44,028]::[InvokeAI]::INFO -->    Models cleared from cache: 0\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:51:44,028]::[InvokeAI]::INFO -->    Cache high water mark: 2.67/6.00G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:51:44,583]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/images/i/bed73d41-5c90-446b-af16-2bdb6534ab80.png HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:51:45,069]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/images/i/bed73d41-5c90-446b-af16-2bdb6534ab80.png/full HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:51:45,184]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/images/?board_id=none&categories=control&categories=mask&categories=user&categories=other&is_intermediate=false&limit=0&offset=0 HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:51:45,185]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/images/?board_id=none&categories=general&is_intermediate=false&limit=0&offset=0 HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:51:45,872]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/images/i/bed73d41-5c90-446b-af16-2bdb6534ab80.png/full HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:51:45,876]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/images/i/bed73d41-5c90-446b-af16-2bdb6534ab80.png/thumbnail HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:52:15,272]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"POST /api/v1/sessions/ HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:52:15,865]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"PUT /api/v1/sessions/3a4a0abe-da91-4071-92ba-24871af1f6f3/invoke?all=true HTTP/1.1\" 202\u001b[0m\n",
            "100% 49/49 [00:16<00:00,  2.91it/s]\n",
            "\u001b[38;20m[2024-01-02 03:52:41,227]::[InvokeAI]::INFO --> Graph stats: 3a4a0abe-da91-4071-92ba-24871af1f6f3\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:52:41,227]::[InvokeAI]::INFO -->                           Node   Calls  Seconds  VRAM Used\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:52:41,228]::[InvokeAI]::INFO -->              main_model_loader     1     0.011s     0.302G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:52:41,228]::[InvokeAI]::INFO -->                      clip_skip     1     0.012s     0.302G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:52:41,228]::[InvokeAI]::INFO -->                    lora_loader     1     0.011s     0.302G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:52:41,228]::[InvokeAI]::INFO -->                         compel     2     2.466s     0.302G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:52:41,228]::[InvokeAI]::INFO -->                     vae_loader     1     0.009s     0.245G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:52:41,229]::[InvokeAI]::INFO -->                       rand_int     1     0.010s     0.245G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:52:41,229]::[InvokeAI]::INFO -->                  range_of_size     1     0.010s     0.245G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:52:41,229]::[InvokeAI]::INFO -->                        iterate     1     0.013s     0.245G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:52:41,229]::[InvokeAI]::INFO -->                          noise     1     0.015s     0.245G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:52:41,230]::[InvokeAI]::INFO -->                denoise_latents     1    19.871s     2.114G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:52:41,230]::[InvokeAI]::INFO -->           metadata_accumulator     1     0.013s     1.859G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:52:41,230]::[InvokeAI]::INFO -->                            l2i     1     2.703s     2.299G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:52:41,230]::[InvokeAI]::INFO --> TOTAL GRAPH EXECUTION TIME:   25.145s\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:52:41,231]::[InvokeAI]::INFO --> RAM used by InvokeAI process: 8.35G (+0.606G)\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:52:41,231]::[InvokeAI]::INFO --> RAM used to load models: 1.99G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:52:41,231]::[InvokeAI]::INFO --> VRAM in use: 0.302G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:52:41,231]::[InvokeAI]::INFO --> RAM cache statistics:\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:52:41,232]::[InvokeAI]::INFO -->    Model cache hits: 10\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:52:41,232]::[InvokeAI]::INFO -->    Model cache misses: 0\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:52:41,232]::[InvokeAI]::INFO -->    Models cached: 7\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:52:41,232]::[InvokeAI]::INFO -->    Models cleared from cache: 0\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:52:41,233]::[InvokeAI]::INFO -->    Cache high water mark: 2.67/6.00G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:52:41,728]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/images/i/49f8af9a-9218-461d-9ef5-b8d7c6093a86.png HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:52:42,229]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/images/i/49f8af9a-9218-461d-9ef5-b8d7c6093a86.png/full HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:52:42,343]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/images/?board_id=none&categories=general&is_intermediate=false&limit=0&offset=0 HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:52:42,461]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/images/?board_id=none&categories=control&categories=mask&categories=user&categories=other&is_intermediate=false&limit=0&offset=0 HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:52:42,462]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/images/i/49f8af9a-9218-461d-9ef5-b8d7c6093a86.png/full HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:52:42,464]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/images/i/49f8af9a-9218-461d-9ef5-b8d7c6093a86.png/thumbnail HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:53:01,641]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/images/i/49f8af9a-9218-461d-9ef5-b8d7c6093a86.png/full HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:53:24,077]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"POST /api/v1/sessions/ HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:53:24,444]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"PUT /api/v1/sessions/d16fa8d4-eb68-4eb8-afd9-d64181dcdf53/invoke?all=true HTTP/1.1\" 202\u001b[0m\n",
            "100% 49/49 [01:01<00:00,  1.25s/it]\n",
            "\u001b[38;20m[2024-01-02 03:54:36,403]::[InvokeAI]::INFO --> Graph stats: d16fa8d4-eb68-4eb8-afd9-d64181dcdf53\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:54:36,403]::[InvokeAI]::INFO -->                           Node   Calls  Seconds  VRAM Used\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:54:36,403]::[InvokeAI]::INFO -->              main_model_loader     1     0.010s     0.302G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:54:36,404]::[InvokeAI]::INFO -->                      clip_skip     1     0.009s     0.302G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:54:36,404]::[InvokeAI]::INFO -->                    lora_loader     1     0.010s     0.302G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:54:36,404]::[InvokeAI]::INFO -->                         compel     2     2.349s     0.302G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:54:36,404]::[InvokeAI]::INFO -->                     vae_loader     1     0.009s     0.245G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:54:36,405]::[InvokeAI]::INFO -->                       rand_int     1     0.011s     0.245G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:54:36,405]::[InvokeAI]::INFO -->                  range_of_size     1     0.009s     0.245G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:54:36,405]::[InvokeAI]::INFO -->                        iterate     1     0.009s     0.245G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:54:36,406]::[InvokeAI]::INFO -->           metadata_accumulator     1     0.010s     0.245G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:54:36,406]::[InvokeAI]::INFO -->                          noise     1     0.018s     0.245G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:54:36,406]::[InvokeAI]::INFO -->                denoise_latents     1    64.408s     2.509G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:54:36,406]::[InvokeAI]::INFO -->                            l2i     1     4.897s     5.371G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:54:36,407]::[InvokeAI]::INFO --> TOTAL GRAPH EXECUTION TIME:   71.750s\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:54:36,407]::[InvokeAI]::INFO --> RAM used by InvokeAI process: 8.44G (+0.534G)\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:54:36,407]::[InvokeAI]::INFO --> RAM used to load models: 1.99G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:54:36,408]::[InvokeAI]::INFO --> VRAM in use: 0.302G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:54:36,408]::[InvokeAI]::INFO --> RAM cache statistics:\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:54:36,408]::[InvokeAI]::INFO -->    Model cache hits: 10\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:54:36,408]::[InvokeAI]::INFO -->    Model cache misses: 0\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:54:36,409]::[InvokeAI]::INFO -->    Models cached: 7\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:54:36,409]::[InvokeAI]::INFO -->    Models cleared from cache: 0\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:54:36,409]::[InvokeAI]::INFO -->    Cache high water mark: 2.67/6.00G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:54:37,040]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/images/i/10dd5d2a-88bd-4a7a-9b28-9c1cb0854b1f.png HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:54:37,566]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/images/?board_id=none&categories=general&is_intermediate=false&limit=0&offset=0 HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:54:37,735]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/images/?board_id=none&categories=control&categories=mask&categories=user&categories=other&is_intermediate=false&limit=0&offset=0 HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:54:37,851]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/images/i/10dd5d2a-88bd-4a7a-9b28-9c1cb0854b1f.png/full HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:54:37,863]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/images/i/10dd5d2a-88bd-4a7a-9b28-9c1cb0854b1f.png/thumbnail HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 03:58:51,591]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/images/?is_intermediate=true HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 04:02:07,850]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"POST /api/v1/sessions/ HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 04:02:08,213]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"PUT /api/v1/sessions/f5eeec3f-796b-4f4d-b535-7604bd632233/invoke?all=true HTTP/1.1\" 202\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 04:02:34,974]::[InvokeAI]::INFO --> Graph stats: f5eeec3f-796b-4f4d-b535-7604bd632233\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 04:02:34,974]::[InvokeAI]::INFO -->                           Node   Calls  Seconds  VRAM Used\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 04:02:34,975]::[InvokeAI]::INFO -->                         esrgan     1    26.757s     12.300G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 04:02:34,975]::[InvokeAI]::INFO --> TOTAL GRAPH EXECUTION TIME:   26.757s\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 04:02:34,975]::[InvokeAI]::INFO --> RAM used by InvokeAI process: 8.42G (+0.003G)\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 04:02:34,975]::[InvokeAI]::INFO --> RAM used to load models: 0.00G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 04:02:34,976]::[InvokeAI]::INFO --> VRAM in use: 0.302G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 04:02:34,976]::[InvokeAI]::INFO --> RAM cache statistics:\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 04:02:34,977]::[InvokeAI]::INFO -->    Model cache hits: 0\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 04:02:34,977]::[InvokeAI]::INFO -->    Model cache misses: 0\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 04:02:34,977]::[InvokeAI]::INFO -->    Models cached: 0\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 04:02:34,977]::[InvokeAI]::INFO -->    Models cleared from cache: 0\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 04:02:34,978]::[InvokeAI]::INFO -->    Cache high water mark: 0.00/0.00G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 04:02:35,650]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/images/i/e5c9fe58-9ab0-47d8-8e94-52095f806aaa.png HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 04:02:36,239]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/images/?board_id=none&categories=general&is_intermediate=false&limit=0&offset=0 HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 04:02:36,544]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/images/?board_id=none&categories=control&categories=mask&categories=user&categories=other&is_intermediate=false&limit=0&offset=0 HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 04:02:36,578]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/images/i/e5c9fe58-9ab0-47d8-8e94-52095f806aaa.png/full HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 04:02:36,638]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/images/i/e5c9fe58-9ab0-47d8-8e94-52095f806aaa.png/thumbnail HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 04:04:33,847]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"POST /api/v1/sessions/ HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 04:04:34,241]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"PUT /api/v1/sessions/00ca1c75-2da3-4d06-9aa2-f54a0c16b2c1/invoke?all=true HTTP/1.1\" 202\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 04:04:43,984]::[InvokeAI]::INFO --> Graph stats: 00ca1c75-2da3-4d06-9aa2-f54a0c16b2c1\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 04:04:43,984]::[InvokeAI]::INFO -->                           Node   Calls  Seconds  VRAM Used\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 04:04:43,985]::[InvokeAI]::INFO -->                         esrgan     1     9.740s     5.111G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 04:04:43,985]::[InvokeAI]::INFO --> TOTAL GRAPH EXECUTION TIME:    9.740s\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 04:04:43,985]::[InvokeAI]::INFO --> RAM used by InvokeAI process: 8.42G (+0.000G)\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 04:04:43,985]::[InvokeAI]::INFO --> RAM used to load models: 0.00G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 04:04:43,986]::[InvokeAI]::INFO --> VRAM in use: 0.302G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 04:04:43,986]::[InvokeAI]::INFO --> RAM cache statistics:\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 04:04:43,986]::[InvokeAI]::INFO -->    Model cache hits: 0\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 04:04:43,987]::[InvokeAI]::INFO -->    Model cache misses: 0\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 04:04:43,987]::[InvokeAI]::INFO -->    Models cached: 0\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 04:04:43,987]::[InvokeAI]::INFO -->    Models cleared from cache: 0\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 04:04:43,987]::[InvokeAI]::INFO -->    Cache high water mark: 0.00/0.00G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 04:04:44,613]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/images/i/ec123304-81cf-4dae-b1c8-1523935eecb5.png HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 04:04:45,260]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/images/i/ec123304-81cf-4dae-b1c8-1523935eecb5.png/full HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 04:04:46,183]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/images/?board_id=none&categories=general&is_intermediate=false&limit=0&offset=0 HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 04:04:46,184]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/images/?board_id=none&categories=control&categories=mask&categories=user&categories=other&is_intermediate=false&limit=0&offset=0 HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 04:04:46,186]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/images/i/ec123304-81cf-4dae-b1c8-1523935eecb5.png/thumbnail HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 04:04:46,186]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/images/i/ec123304-81cf-4dae-b1c8-1523935eecb5.png/full HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 04:05:46,465]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/images/i/ec123304-81cf-4dae-b1c8-1523935eecb5.png/full HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 04:10:40,961]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"POST /api/v1/sessions/ HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 04:10:41,353]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"PUT /api/v1/sessions/e38caf16-695a-4154-b0ac-e5fb2f4c43df/invoke?all=true HTTP/1.1\" 202\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 04:10:46,314]::[InvokeAI]::INFO --> Graph stats: e38caf16-695a-4154-b0ac-e5fb2f4c43df\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 04:10:46,315]::[InvokeAI]::INFO -->                           Node   Calls  Seconds  VRAM Used\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 04:10:46,315]::[InvokeAI]::INFO -->                         esrgan     1     4.959s     5.065G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 04:10:46,315]::[InvokeAI]::INFO --> TOTAL GRAPH EXECUTION TIME:    4.959s\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 04:10:46,316]::[InvokeAI]::INFO --> RAM used by InvokeAI process: 8.42G (+0.000G)\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 04:10:46,316]::[InvokeAI]::INFO --> RAM used to load models: 0.00G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 04:10:46,316]::[InvokeAI]::INFO --> VRAM in use: 0.302G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 04:10:46,317]::[InvokeAI]::INFO --> RAM cache statistics:\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 04:10:46,317]::[InvokeAI]::INFO -->    Model cache hits: 0\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 04:10:46,317]::[InvokeAI]::INFO -->    Model cache misses: 0\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 04:10:46,317]::[InvokeAI]::INFO -->    Models cached: 0\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 04:10:46,318]::[InvokeAI]::INFO -->    Models cleared from cache: 0\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 04:10:46,318]::[InvokeAI]::INFO -->    Cache high water mark: 0.00/0.00G\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 04:10:46,768]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/images/i/aec3ed8f-a44c-49e7-b109-fd0431558fda.png HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 04:10:47,242]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/images/?board_id=none&categories=general&is_intermediate=false&limit=0&offset=0 HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 04:10:47,552]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/images/?board_id=none&categories=control&categories=mask&categories=user&categories=other&is_intermediate=false&limit=0&offset=0 HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 04:10:47,608]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/images/i/aec3ed8f-a44c-49e7-b109-fd0431558fda.png/full HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 04:10:47,620]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/images/i/aec3ed8f-a44c-49e7-b109-fd0431558fda.png/thumbnail HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-02 04:11:47,132]::[uvicorn.access]::INFO --> 110.136.55.67:0 - \"GET /api/v1/images/i/aec3ed8f-a44c-49e7-b109-fd0431558fda.png/full HTTP/1.1\" 200\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "#@markdown # **STEP 3**\n",
        "#@markdown ## Run StableDiffusion InvokeAI\n",
        "\n",
        "import os\n",
        "import shlex\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "from typing import Union\n",
        "clear_output()\n",
        "\n",
        "\n",
        "id_rsa_file = \"/content/InvokeAI/id_rsa\"\n",
        "id_rsa_pub_file = \"/content/InvokeAI/id_rsa.pub\"\n",
        "if os.path.exists(id_rsa_file):\n",
        "    os.remove(id_rsa_file)\n",
        "if os.path.exists(id_rsa_pub_file):\n",
        "    os.remove(id_rsa_pub_file)\n",
        "clear_output()\n",
        "\n",
        "def gen_key(path: Union[str, Path]) -> None:\n",
        "    path = Path(path)\n",
        "    arg_string = f'ssh-keygen -t rsa -b 4096 -N \"\" -q -f {path.as_posix()}'\n",
        "    args = shlex.split(arg_string)\n",
        "    subprocess.run(args, check=False)\n",
        "    path.chmod(0o600)\n",
        "\n",
        "ssh_name = \"id_rsa\"\n",
        "ssh_path = Path(os.path.dirname(os.getcwd())) / ssh_name\n",
        "gen_key(ssh_path)\n",
        "clear_output()\n",
        "\n",
        "import threading\n",
        "def tunnel():\n",
        "  !ssh -R 80:127.0.0.1:9090 -o StrictHostKeyChecking=no -i /content/id_rsa remote.moe\n",
        "threading.Thread(target=tunnel, daemon=True).start()\n",
        "\n",
        "%cd /content/InvokeAI/\n",
        "!python /content/InvokeAI/scripts/invokeai-web.py --root /content/db"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}