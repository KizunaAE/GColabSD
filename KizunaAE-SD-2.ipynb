{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KizunaAE/GColabSD/blob/main/KizunaAE-SD-2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anqY-GmKTL8V"
      },
      "source": [
        "# **StableDiffusion InvokeAI Base Cloud version**\n",
        "\n",
        "\n",
        "\n",
        "_You don't need additional Google Drive storage because uploaded models are not stored on your Google Drive. After the session ends, all data will be deleted._"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JQ5qVdNPFqYJ"
      },
      "outputs": [],
      "source": [
        "#@markdown # **STEP 1**\n",
        "#@markdown ## Requirements\n",
        "#@markdown It might finished with error but is not the error, just execute the next cell\n",
        "\n",
        "from IPython.display import clear_output\n",
        "\n",
        "%cd /content\n",
        "!git clone https://github.com/rocketpal/InvokeAI\n",
        "!pip install -q dependency_injector diffusers einops eventlet facexlib flask_cors flask_socketio flaskwebgui getpass_asterisk huggingface-hub\n",
        "!pip install -q kornia omegaconf pudb pyreadline3 pytorch-lightning realesrgan streamlit taming-transformers-rom1504 test-tube torch-fidelity\n",
        "!pip install -q torchmetrics transformers picklescan\n",
        "!pip install -q pillow xformers==0.0.22 triton==2.0.0 -U\n",
        "clear_output()\n",
        "\n",
        "!pip install -q git+https://github.com/invoke-ai/GFPGAN@basicsr-1.4.2#egg=gfpgan\n",
        "!pip install -q git+https://github.com/openai/CLIP.git@main#egg=clip\n",
        "!pip install -q git+https://github.com/Birch-san/k-diffusion.git@mps#egg=k-diffusion\n",
        "!pip install -q git+https://github.com/invoke-ai/clipseg.git@relaxed-python-requirement#egg=clipseg\n",
        "!pip install -q git+https://github.com/invoke-ai/PyPatchMatch@0.1.4#egg=pypatchmatch\n",
        "%cd /content/InvokeAI/\n",
        "!pip install -q -e .\n",
        "clear_output()\n",
        "\n",
        "\n",
        "!wget https://raw.githubusercontent.com/rocketpal/InvokeAI-colab/main/INITIAL_MODELS.yaml -O /content/InvokeAI/invokeai/configs/INITIAL_MODELS.yaml\n",
        "clear_output()\n",
        "\n",
        "print('\u001b[1;32mDone!')\n",
        "\n",
        "!pip install python-socketio==5.9.0\n",
        "clear_output()\n",
        "\n",
        "#exit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "aBZ0AbI-U_zk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fe93b62-44b6-4e43-a103-8843642df319"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;32mDone! All models downloaded successfully ðŸ™ƒ\n"
          ]
        }
      ],
      "source": [
        "#@markdown # **STEP 2**\n",
        "#@markdown ## Downloading models _(checkpoints, LoRAs, ControlNets, etc.)_\n",
        "#@markdown To configure the downloading of models, edit this file:\n",
        "#@markdown _/content/InvokeAI/invokeai/configs/INITIAL_MODELS.yaml_\n",
        "\n",
        "#@markdown P.S. It's fully explained in the tutorial.\n",
        "from IPython.display import clear_output\n",
        "\n",
        "%cd /content/InvokeAI/\n",
        "!python /content/InvokeAI/scripts/invokeai-model-install.py --root_dir /content/db --yes\n",
        "\n",
        "clear_output()\n",
        "print('\u001b[1;32mDone! All models downloaded successfully ðŸ™ƒ')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "id": "AuFwU5t8POIS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "859f5481-6038-430f-da83-572dbf203832"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " [1;32m Model just loaded! ðŸš€\n"
          ]
        }
      ],
      "source": [
        "#@markdown ### Load Model (option2)\n",
        "model_link = \"https://civitai.com/api/download/models/128713?type=Model&format=SafeTensor&size=pruned&fp=fp16\" # @param {type:\"string\"}\n",
        "\n",
        "!wget -O /content/db/models/sd-1/main/model.safetensors \"{model_link}\"\n",
        "\n",
        "clear_output()\n",
        "print(' [1;32m Model just loaded! ðŸš€')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWoTrZLRP5zh",
        "outputId": "3eb7eeae-c7ff-4290-9268-1a17c6dc3949"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/InvokeAI\n",
            "Warning: Permanently added 'remote.moe' (ED25519) to the list of known hosts.\n",
            "\u001b[1mhttp\u001b[0m (80)\n",
            "http://2xe63gzksokikj2ecpyzhtgdwiflk7tgr3uuupzmkp4g62d5gugq.remote.moe/\n",
            "\n",
            "$\n",
            " \n",
            "2024-01-01 16:00:37.420374: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-01-01 16:00:37.420435: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-01-01 16:00:37.426674: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-01-01 16:00:39.309461: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional_tensor.py:5: UserWarning: The torchvision.transforms.functional_tensor module is deprecated in 0.15 and will be **removed in 0.17**. Please don't rely on it. You probably just need to use APIs in torchvision.transforms.functional or in torchvision.transforms.v2.functional.\n",
            "  warnings.warn(\n",
            ">> patchmatch.patch_match: INFO - Compiling and loading c extensions from \"/usr/local/lib/python3.10/dist-packages/patchmatch\".\n",
            ">> patchmatch.patch_match: WARNING - patchmatch failed to load or compile.\n",
            ">> patchmatch.patch_match: WARNING - Refer to https://github.com/invoke-ai/InvokeAI/blob/main/docs/installation/INSTALL_PATCHMATCH.md for installation instructions.\n",
            "\u001b[38;20m[2024-01-01 16:00:48,901]::[InvokeAI]::INFO --> Patchmatch not loaded (nonfatal)\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:00:50,326]::[uvicorn.error]::INFO --> Started server process [5055]\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:00:50,327]::[uvicorn.error]::INFO --> Waiting for application startup.\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:00:50,327]::[InvokeAI]::INFO --> InvokeAI version 3.1.0\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:00:50,327]::[InvokeAI]::INFO --> Root directory = /content/db\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:00:50,545]::[InvokeAI]::INFO --> GPU device = cuda Tesla T4\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:00:50,548]::[InvokeAI]::INFO --> Scanning /content/db/models for new models\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:00:50,947]::[InvokeAI]::INFO --> Scanned 6 files and directories, imported 0 models\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:00:50,949]::[InvokeAI]::INFO --> Model manager service initialized\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:00:50,982]::[uvicorn.error]::INFO --> Application startup complete.\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:00:50,982]::[uvicorn.error]::INFO --> Uvicorn running on http://127.0.0.1:9090 (Press CTRL+C to quit)\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:02:19,598]::[uvicorn.access]::INFO --> 110.138.16.84:0 - \"GET / HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:02:19,993]::[uvicorn.access]::INFO --> 110.138.16.84:0 - \"GET /assets/index-08cda350.js HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:02:26,483]::[uvicorn.access]::INFO --> 110.138.16.84:0 - \"GET /locales/en.json HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:02:26,720]::[uvicorn.access]::INFO --> 110.138.16.84:0 - \"GET /assets/ThemeLocaleProvider-707a230a.js HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:02:26,722]::[uvicorn.access]::INFO --> 110.138.16.84:0 - \"GET /assets/ThemeLocaleProvider-90f0fcd3.css HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:02:26,723]::[uvicorn.access]::INFO --> 110.138.16.84:0 - \"GET /assets/menu-3d10c968.js HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:02:27,209]::[uvicorn.access]::INFO --> 110.138.16.84:0 - \"GET /assets/logo-13003d72.png HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:02:27,647]::[uvicorn.access]::INFO --> 110.138.16.84:0 - \"GET /assets/App-6125620a.css HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:02:27,660]::[uvicorn.access]::INFO --> 110.138.16.84:0 - \"GET /assets/App-78495256.js HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:02:27,973]::[uvicorn.access]::INFO --> 110.138.16.84:0 - \"GET /assets/favicon-0d253ced.ico HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:02:31,323]::[uvicorn.access]::INFO --> 110.138.16.84:0 - \"GET /socket.io/?EIO=4&transport=polling&t=Op5moAQ HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:02:31,418]::[uvicorn.access]::INFO --> 110.138.16.84:0 - \"GET /api/v1/app/version HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:02:39,918]::[InvokeAI]::INFO --> NSFW checker initialized\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:02:39,918]::[uvicorn.access]::INFO --> 110.138.16.84:0 - \"GET /api/v1/app/config HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:02:39,920]::[uvicorn.access]::INFO --> 110.138.16.84:0 - \"GET /api/v1/models/?model_type=embedding HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:02:39,921]::[uvicorn.access]::INFO --> 110.138.16.84:0 - \"GET /api/v1/models/?base_models=sd-1&base_models=sd-2&base_models=sdxl&model_type=onnx HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:02:39,922]::[uvicorn.access]::INFO --> 110.138.16.84:0 - \"GET /api/v1/models/?base_models=sd-1&base_models=sd-2&base_models=sdxl&model_type=main HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:02:39,924]::[uvicorn.access]::INFO --> 110.138.16.84:0 - \"GET /api/v1/models/?model_type=vae HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:02:39,925]::[uvicorn.error]::INFO --> ('110.138.16.84', 0) - \"WebSocket /socket.io/?EIO=4&transport=websocket&sid=VEiwf4FjvejMOQKJAAAA\" [accepted]\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:02:39,926]::[uvicorn.error]::INFO --> connection open\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:02:39,927]::[uvicorn.access]::INFO --> 110.138.16.84:0 - \"GET /assets/inter-latin-wght-normal-450f3ba4.woff2 HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:02:40,220]::[uvicorn.access]::INFO --> 110.138.16.84:0 - \"GET /api/v1/models/?model_type=controlnet HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:02:40,221]::[uvicorn.access]::INFO --> 110.138.16.84:0 - \"GET /api/v1/models/?model_type=lora HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:02:40,267]::[uvicorn.access]::INFO --> 110.138.16.84:0 - \"GET /api/v1/images/?board_id=none&categories=general&is_intermediate=false&limit=0&offset=0 HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:02:40,336]::[uvicorn.access]::INFO --> 110.138.16.84:0 - \"GET /api/v1/images/?board_id=none&categories=control&categories=mask&categories=user&categories=other&is_intermediate=false&limit=0&offset=0 HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:02:40,337]::[uvicorn.access]::INFO --> 110.138.16.84:0 - \"GET /api/v1/boards/?all=true HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:02:40,519]::[uvicorn.access]::INFO --> 110.138.16.84:0 - \"GET /api/v1/images/?board_id=none&categories=general&is_intermediate=false&limit=100&offset=0 HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:02:40,522]::[uvicorn.access]::INFO --> 110.138.16.84:0 - \"POST /socket.io/?EIO=4&transport=polling&t=Op5moFX&sid=VEiwf4FjvejMOQKJAAAA HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:02:40,635]::[uvicorn.access]::INFO --> 110.138.16.84:0 - \"GET /socket.io/?EIO=4&transport=polling&t=Op5moFc&sid=VEiwf4FjvejMOQKJAAAA HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:02:42,556]::[uvicorn.access]::INFO --> 110.138.16.84:0 - \"GET /openapi.json HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:02:42,558]::[uvicorn.access]::INFO --> 110.138.16.84:0 - \"GET /api/v1/models/?model_type=lora HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:02:42,559]::[uvicorn.access]::INFO --> 110.138.16.84:0 - \"GET /api/v1/models/?base_models=sd-1&base_models=sd-2&base_models=sdxl&model_type=main HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:02:42,560]::[uvicorn.access]::INFO --> 110.138.16.84:0 - \"GET /api/v1/models/?model_type=vae HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:02:42,561]::[uvicorn.access]::INFO --> 110.138.16.84:0 - \"GET /api/v1/models/?model_type=embedding HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:02:42,563]::[uvicorn.access]::INFO --> 110.138.16.84:0 - \"GET /api/v1/models/?model_type=controlnet HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:02:43,317]::[uvicorn.access]::INFO --> 110.138.16.84:0 - \"GET /api/v1/app/config HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:02:43,318]::[uvicorn.access]::INFO --> 110.138.16.84:0 - \"GET /api/v1/app/version HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:04:18,082]::[uvicorn.access]::INFO --> 110.138.16.84:0 - \"POST /api/v1/images/upload?image_category=user&is_intermediate=false HTTP/1.1\" 201\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:04:18,438]::[uvicorn.access]::INFO --> 110.138.16.84:0 - \"GET /api/v1/images/?board_id=none&categories=control&categories=mask&categories=user&categories=other&is_intermediate=false&limit=0&offset=0 HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:04:18,554]::[uvicorn.access]::INFO --> 110.138.16.84:0 - \"GET /api/v1/images/?board_id=none&categories=general&is_intermediate=false&limit=0&offset=0 HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:04:18,559]::[uvicorn.access]::INFO --> 110.138.16.84:0 - \"GET /api/v1/images/i/0963c673-0324-4055-9050-adc0e6868ab3.png/full HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:05:15,471]::[uvicorn.access]::INFO --> 110.138.16.84:0 - \"POST /api/v1/images/upload?image_category=user&is_intermediate=false HTTP/1.1\" 201\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:05:15,853]::[uvicorn.access]::INFO --> 110.138.16.84:0 - \"GET /api/v1/images/?board_id=none&categories=general&is_intermediate=false&limit=0&offset=0 HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:05:15,969]::[uvicorn.access]::INFO --> 110.138.16.84:0 - \"GET /api/v1/images/?board_id=none&categories=control&categories=mask&categories=user&categories=other&is_intermediate=false&limit=0&offset=0 HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:05:17,086]::[uvicorn.access]::INFO --> 110.138.16.84:0 - \"POST /api/v1/sessions/ HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:05:17,087]::[uvicorn.access]::INFO --> 110.138.16.84:0 - \"GET /api/v1/images/i/631c0056-cd4e-447c-a15e-8a8106d55d67.png/full HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:05:17,425]::[uvicorn.access]::INFO --> 110.138.16.84:0 - \"PUT /api/v1/sessions/1d27cf0c-e46c-4245-80d8-5dec0e2da9a0/invoke?all=true HTTP/1.1\" 202\u001b[0m\n",
            "Downloading body_pose_model.pth: 100% 209M/209M [00:01<00:00, 193MB/s]\n",
            "Downloading hand_pose_model.pth: 100% 147M/147M [00:00<00:00, 203MB/s]\n",
            "Downloading facenet.pth: 100% 154M/154M [00:02<00:00, 65.3MB/s]\n",
            "\u001b[38;20m[2024-01-01 16:05:28,042]::[InvokeAI]::INFO --> Graph stats: 1d27cf0c-e46c-4245-80d8-5dec0e2da9a0\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:05:28,042]::[InvokeAI]::INFO -->                           Node   Calls  Seconds  VRAM Used\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:05:28,043]::[InvokeAI]::INFO -->       openpose_image_processor     1    10.614s     0.000G\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:05:28,043]::[InvokeAI]::INFO --> TOTAL GRAPH EXECUTION TIME:   10.614s\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:05:28,043]::[InvokeAI]::INFO --> RAM used by InvokeAI process: 2.96G (+0.613G)\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:05:28,043]::[InvokeAI]::INFO --> RAM used to load models: 0.00G\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:05:28,044]::[InvokeAI]::INFO --> VRAM in use: 0.000G\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:05:28,044]::[InvokeAI]::INFO --> RAM cache statistics:\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:05:28,044]::[InvokeAI]::INFO -->    Model cache hits: 0\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:05:28,044]::[InvokeAI]::INFO -->    Model cache misses: 0\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:05:28,045]::[InvokeAI]::INFO -->    Models cached: 0\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:05:28,045]::[InvokeAI]::INFO -->    Models cleared from cache: 0\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:05:28,045]::[InvokeAI]::INFO -->    Cache high water mark: 0.00/0.00G\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:05:28,520]::[uvicorn.access]::INFO --> 110.138.16.84:0 - \"GET /api/v1/images/i/a660b0b6-0320-4ea9-82c6-c752589d8484.png HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:05:28,889]::[uvicorn.access]::INFO --> 110.138.16.84:0 - \"GET /api/v1/images/i/a660b0b6-0320-4ea9-82c6-c752589d8484.png/full HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:06:29,173]::[uvicorn.access]::INFO --> 110.138.16.84:0 - \"POST /api/v1/images/upload?image_category=user&is_intermediate=false HTTP/1.1\" 201\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:06:29,514]::[uvicorn.access]::INFO --> 110.138.16.84:0 - \"GET /api/v1/images/?board_id=none&categories=general&is_intermediate=false&limit=0&offset=0 HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:06:29,632]::[uvicorn.access]::INFO --> 110.138.16.84:0 - \"GET /api/v1/images/?board_id=none&categories=control&categories=mask&categories=user&categories=other&is_intermediate=false&limit=0&offset=0 HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:06:29,638]::[uvicorn.access]::INFO --> 110.138.16.84:0 - \"GET /api/v1/images/i/377ba2c9-f994-4e2a-97a8-bfc8a78380c3.png/full HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:06:29,805]::[uvicorn.access]::INFO --> 110.138.16.84:0 - \"POST /api/v1/sessions/ HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:06:30,688]::[uvicorn.access]::INFO --> 110.138.16.84:0 - \"PUT /api/v1/sessions/e4655a97-bb02-4fef-82e4-a2c5defa9ca0/invoke?all=true HTTP/1.1\" 202\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:06:33,708]::[InvokeAI]::INFO --> Graph stats: e4655a97-bb02-4fef-82e4-a2c5defa9ca0\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:06:33,708]::[InvokeAI]::INFO -->                           Node   Calls  Seconds  VRAM Used\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:06:33,708]::[InvokeAI]::INFO -->       openpose_image_processor     1     3.017s     0.000G\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:06:33,709]::[InvokeAI]::INFO --> TOTAL GRAPH EXECUTION TIME:    3.017s\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:06:33,709]::[InvokeAI]::INFO --> RAM used by InvokeAI process: 2.96G (+0.001G)\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:06:33,709]::[InvokeAI]::INFO --> RAM used to load models: 0.00G\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:06:33,710]::[InvokeAI]::INFO --> VRAM in use: 0.000G\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:06:33,710]::[InvokeAI]::INFO --> RAM cache statistics:\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:06:33,710]::[InvokeAI]::INFO -->    Model cache hits: 0\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:06:33,710]::[InvokeAI]::INFO -->    Model cache misses: 0\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:06:33,711]::[InvokeAI]::INFO -->    Models cached: 0\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:06:33,711]::[InvokeAI]::INFO -->    Models cleared from cache: 0\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:06:33,711]::[InvokeAI]::INFO -->    Cache high water mark: 0.00/0.00G\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:06:34,024]::[uvicorn.access]::INFO --> 110.138.16.84:0 - \"GET /api/v1/images/i/f7ff2cf0-7083-4221-a931-b51d56758ac1.png HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:06:34,399]::[uvicorn.access]::INFO --> 110.138.16.84:0 - \"GET /api/v1/images/i/f7ff2cf0-7083-4221-a931-b51d56758ac1.png/full HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:07:02,230]::[uvicorn.access]::INFO --> 110.138.16.84:0 - \"POST /api/v1/sessions/ HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:07:02,568]::[uvicorn.access]::INFO --> 110.138.16.84:0 - \"PUT /api/v1/sessions/d6725c16-c1aa-4c9b-8615-0227878c05ca/invoke?all=true HTTP/1.1\" 202\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:07:02,639]::[InvokeAI]::INFO --> Converting /content/db/models/sd-1/main/model.safetensors to diffusers format\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:07:35,328]::[InvokeAI]::INFO --> Loading model /content/db/models/.cache/40c5bb4fa32829427d82ee66a4dcccdc, type sd-1:main:tokenizer\u001b[0m\n",
            "\u001b[38;20m[2024-01-01 16:07:36,281]::[InvokeAI]::INFO --> Loading model /content/db/models/.cache/40c5bb4fa32829427d82ee66a4dcccdc, type sd-1:main:text_encoder\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "#@markdown # **STEP 3**\n",
        "#@markdown ## Run StableDiffusion InvokeAI\n",
        "\n",
        "import os\n",
        "import shlex\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "from typing import Union\n",
        "clear_output()\n",
        "\n",
        "\n",
        "id_rsa_file = \"/content/InvokeAI/id_rsa\"\n",
        "id_rsa_pub_file = \"/content/InvokeAI/id_rsa.pub\"\n",
        "if os.path.exists(id_rsa_file):\n",
        "    os.remove(id_rsa_file)\n",
        "if os.path.exists(id_rsa_pub_file):\n",
        "    os.remove(id_rsa_pub_file)\n",
        "clear_output()\n",
        "\n",
        "def gen_key(path: Union[str, Path]) -> None:\n",
        "    path = Path(path)\n",
        "    arg_string = f'ssh-keygen -t rsa -b 4096 -N \"\" -q -f {path.as_posix()}'\n",
        "    args = shlex.split(arg_string)\n",
        "    subprocess.run(args, check=True)\n",
        "    path.chmod(0o600)\n",
        "\n",
        "ssh_name = \"id_rsa\"\n",
        "ssh_path = Path(os.path.dirname(os.getcwd())) / ssh_name\n",
        "gen_key(ssh_path)\n",
        "clear_output()\n",
        "\n",
        "import threading\n",
        "def tunnel():\n",
        "  !ssh -R 80:127.0.0.1:9090 -o StrictHostKeyChecking=no -i /content/id_rsa remote.moe\n",
        "threading.Thread(target=tunnel, daemon=True).start()\n",
        "\n",
        "%cd /content/InvokeAI/\n",
        "!python /content/InvokeAI/scripts/invokeai-web.py --root /content/db"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}